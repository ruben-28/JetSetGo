# ============================================================================
# JetSetGo Backend - Environment Variables
# ============================================================================
# Copy this file to .env and fill in your API keys
# .env is gitignored and should never be committed

# ----------------------------------------------------------------------------
# Database Configuration (SQL Server Cloud)
# ----------------------------------------------------------------------------
# SQL Server connection details for somee.com
DB_SERVER=jetsetgo_db.mssql.somee.com
DB_NAME=jetsetgo_db
DB_USER=ethan5_SQLLogin_1
DB_PASSWORD=YOUR_PASSWORD_HERE

# ----------------------------------------------------------------------------
# Authentication & Security
# ----------------------------------------------------------------------------
# CRITICAL: Generate a secure secret for production
# Command: python -c "import secrets; print(secrets.token_urlsafe(32))"
JWT_SECRET=CHANGE_ME_SUPER_SECRET
JWT_EXPIRE_MINUTES=1440

# ----------------------------------------------------------------------------
# Travel API Configuration
# ----------------------------------------------------------------------------
# Leave empty to use MOCK MODE (fake data for testing)
TRAVEL_API_KEY=
TRAVEL_API_BASE_URL=https://api.travel-provider.com/v1

# ----------------------------------------------------------------------------
# HuggingFace Configuration
# ----------------------------------------------------------------------------
# Get your token from: https://huggingface.co/settings/tokens
# Leave empty to use MOCK MODE (fake sentiment analysis)
HF_API_TOKEN=

# ----------------------------------------------------------------------------
# Gateway Configuration
# ----------------------------------------------------------------------------
# HTTP request timeout in seconds
GATEWAY_TIMEOUT=30

# Maximum number of retry attempts for failed requests
GATEWAY_MAX_RETRIES=3

# Initial retry delay in seconds (exponential backoff)
GATEWAY_RETRY_DELAY=1.0

# ----------------------------------------------------------------------------
# Application Configuration
# ----------------------------------------------------------------------------
# Enable debug mode (verbose logging)
DEBUG=True

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# ----------------------------------------------------------------------------
# LLM Configuration (for AI Assistant)
# ----------------------------------------------------------------------------
# LLM Provider: "ollama" or "openai"
LLM_PROVIDER=ollama

# Ollama Configuration (if LLM_PROVIDER=ollama)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:3b
OLLAMA_TIMEOUT=30  # seconds

# Prompt validation
MAX_PROMPT_CHARS=8000  # Maximum characters for user prompts

# OpenAI Configuration (if LLM_PROVIDER=openai) - Future
# OPENAI_API_KEY=sk-...
# OPENAI_MODEL=gpt-4o-mini
# OPENAI_TIMEOUT=30

# ----------------------------------------------------------------------------
# Ollama Setup Instructions
# ----------------------------------------------------------------------------
# 1. Install Ollama: https://ollama.ai/download
# 2. Start Ollama server: ollama serve
# 3. Pull the model: ollama pull qwen2.5:3b
# 4. Verify: ollama list (should show qwen2.5:3b)
# 5. Start backend: uvicorn app.main:app --reload
# 6. Test: POST http://localhost:8000/api/ai/consult

# ----------------------------------------------------------------------------
# Notes
# ----------------------------------------------------------------------------
# - Mock mode is automatically activated when API keys are missing
# - All gateways will log warnings when running in mock mode
# - For production, set DEBUG=False and configure proper API keys
# - LLM fallback to mock if Ollama unavailable (prevents crashes)
