"""
Assistant Orchestrator - Moteur de D√©cision Central

Refactoris√© pour utiliser l'infrastructure de gateway existante :
- app.gateway.OllamaGateway pour la g√©n√©ration de langage naturel
- app.gateway.HFGateway pour l'analyse (peut √™tre √©tendu pour la classification d'intention)

Flux :
1. Recevoir le message utilisateur
2. Analyser l'intention (matching de mots-cl√©s simple pour l'instant, peut int√©grer mod√®les HF plus tard)
3. D√©cider de l'action bas√©e sur l'intention
4. G√©n√©rer la r√©ponse en langage naturel avec Ollama
5. Retourner l'action + r√©ponse au desktop
"""
from typing import Dict, Optional, List
import logging
from app.gateway.ollama_gateway import OllamaGateway
from app.gateway.huggingface_gateway import HuggingFaceGateway
from app.gateway.travel_provider import TravelProvider

logger = logging.getLogger(__name__)


class AssistantOrchestrator:
    """
    Moteur de d√©cision central pour l'assistant IA.
    Utilise l'infrastructure de gateway existante.
    """
    
    def __init__(self):
        self.travel_provider = TravelProvider()
    
    async def process_message(self, user_message: str, user_id: int) -> Dict:
        """
        Logique d'orchestration principale.
        
        Retourne :
            {
                "action": str,  # "navigate", "display_results", "chat_only"
                "target_view": str | None,  # "flights", "hotels", "packages"
                "prefill_data": {...} | None,
                "search_results": [...] | None,
                "response_text": str,
                "metadata": {...}
            }
        """
        logger.info(f"Traitement du message de l'utilisateur {user_id} : {user_message}")
        
        # √âtape 1 : Analyser l'intention en utilisant un simple matching de mots-cl√©s
        # TODO : Peut √™tre am√©lior√© avec la classification zero-shot HF plus tard
        analysis = await self._analyze_intent(user_message)
        
        intent = analysis["intent"]
        entities = analysis["entities"]
        
        logger.info(f"Intention : {intent}, Entit√©s : {entities}")
        
        # √âtape 2 : Routage bas√© sur l'intention
        if intent == "flight_search":
            return await self._handle_flight_search(entities, user_message)
        
        elif intent == "hotel_search":
            return await self._handle_hotel_search(entities, user_message)
        
        elif intent == "package_search":
            return await self._handle_package_search(entities, user_message)
        
        elif intent == "booking_history":
            return await self._handle_booking_history(entities, user_message)
            
        elif intent == "budget_advice":
            return await self._handle_budget_advice(entities, user_message)
        
        elif intent == "inspiration":
            return await self._handle_inspiration(entities, user_message)
        
        else:
            # Conversation g√©n√©rale
            return await self._handle_general_conversation(user_message)
    
    async def _analyze_intent(self, message: str) -> Dict:
        """
        Analyser l'intention en utilisant une approche hybride (HF Zero-Shot + Regex Fallback).
        """
        # 1. Essayer la classification Zero-Shot Hugging Face
        async with HuggingFaceGateway() as gateway:
            # Les candidats sont maintenant cod√©s en dur dans le Gateway
            
            result = await gateway.classify_intent(message)
            
            # Format du r√©sultat : {'intent': '...', 'confidence': 0.9}
            # La logique de seuil est d√©j√† g√©r√©e dans le Gateway
            intent = result["intent"]
            confidence = result["confidence"]
            
            logger.info(f"Intention d√©tect√©e '{intent}' avec confiance {confidence:.2f}")
                
        # 3. Extraire les entit√©s (Hybride : HF NER + Regex)
        entities = await self._extract_entities(message)
        
        return {
            "intent": intent,
            "entities": entities
        }
    
    async def _extract_entities(self, message: str) -> Dict:
        """
        Extraction d'Entit√©s Hybride :
        - LOC (Destination/Origine) : Utilise Hugging Face NER (xlm-roberta)
        - DATES/TRAVELERS : Utilise Regex (plus fiable pour la structure)
        """
        # 1. Extraction Regex (Dates, Voyageurs, Budget, Pr√©f√©rences)
        # Nous r√©utilisons la logique du mock/helper Gateway qui a de bons patterns regex
        # Ou l'impl√©mentons ici. Pour une s√©paration propre, appelons les helpers du Gateway
        # via une m√©thode priv√©e ou r√©impl√©mentons simplement des regex ici.
        # Gardons-le robuste et simple ici.
        
        # Regex de date (manuel pour l'instant pour √©viter l'enfer des d√©pendances si dateparser manquant)
        import re
        date_pattern = r"(janvier|f√©vrier|mars|avril|mai|juin|juillet|ao√ªt|septembre|octobre|novembre|d√©cembre|demain|semaine prochaine|\d{1,2}[/-]\d{1,2})"
        date_match = re.search(date_pattern, message.lower())
        dates = {"raw": date_match.group(0)} if date_match else None
        
        # 2. HF NER (pour Lieux - Locations)
        destination = None
        async with HuggingFaceGateway() as gateway:
            entities_list = await gateway.extract_entities(message)
            # Filtrer pour LOC
            locations = [e["word"] for e in entities_list if e.get("entity_group") == "LOC"]
            if locations:
                # Na√Øf : prendre le premier lieu comme destination
                destination = locations[0]
        
        # Fallback pour la destination si NER a √©chou√©
        if not destination:
            # Liste des villes majeures (Fallback)
            cities = [
                "Paris", "London", "New York", "Tokyo", "Rome", "Barcelona",
                "Madrid", "Berlin", "Amsterdam", "Prague", "Vienna", "Budapest",
                "Athens", "Istanbul", "Dubai", "Bangkok", "Singapore", "Sydney",
                "Los Angeles", "Miami", "Toronto", "Montreal", "Cancun", "Marrakech"
            ]
            for city in cities:
                if city.lower() in message.lower():
                    destination = city
                    break

        return {
            "destination": destination,
            "period": dates["raw"] if dates else None, # Compatibilit√© h√©rit√©e
            "preferences": [], # Peut √™tre am√©lior√© plus tard
            "dates": dates,
            "travelers": None 
        }
    
    async def _generate_ollama_response(self, prompt_type: str, context: Dict) -> str:
        """G√©n√©rer une r√©ponse en langage naturel utilisant Ollama."""
        
        # Construire les messages pour l'API de chat Ollama
        # Forcer explicitement la langue fran√ßaise pour √©viter les hallucinations/m√©langes de langues
        system_message = (
            "Tu es un assistant de voyage intelligent et sympathique pour JetSetGo. "
            "Ta langue de sortie est STRICTEMENT le FRAN√áAIS. "
            "M√™me si l'utilisateur parle anglais ou une autre langue, tu dois r√©pondre en fran√ßais. "
            "Sois enthousiaste, mais reste √©quilibr√© et objectif, notamment concernant la s√©curit√© et la situation politique."
        )
        
        if prompt_type == "navigate_to_flights":
            user_prompt = f"L'utilisateur veut chercher des vols pour {context.get('destination', 'une destination')}. Confirme que tu vas l'amener √† la recherche de vols. Sois bref (1 phrase)."
        
        elif prompt_type == "navigate_to_hotels":
            user_prompt = f"L'utilisateur veut chercher des h√¥tels √† {context.get('destination', 'une destination')}. Confirme que tu vas l'amener √† la recherche d'h√¥tels. Sois bref (1 phrase)."
        
        elif prompt_type == "navigate_to_packages":
            user_prompt = f"L'utilisateur veut chercher des packages pour {context.get('destination', 'une destination')}. Confirme que tu vas l'amener √† la recherche de packages. Sois bref (1 phrase)."
        
        elif prompt_type == "clarification":
            missing = context.get('missing', 'une information')
            user_prompt = f"Demande poliment √† l'utilisateur de pr√©ciser {missing}. Sois bref (1 phrase)."
        
        elif prompt_type == "inspiration":
            # Utiliser le contexte extrait
            period = context.get('period', '')
            prefs = context.get('preferences', [])
            user_msg = context.get('message', '')
            
            # Construire le texte contextualis√©
            period_text = f" pour {period}" if period else ""
            prefs_text = f" (pr√©f√©rences: {', '.join(prefs)})" if prefs else ""
            
            user_prompt = (
                f"L'utilisateur dit : '{user_msg}'\n"
                f"CONTEXTE: Il cherche des id√©es de voyage{period_text}{prefs_text}.\n\n"
                f"INSTRUCTIONS :\n"
                f"1. Si la demande concerne un pays sp√©cifique ou demande un avis (ex: 'est-ce que X est dangereux ?', 'avis sur Y') :\n"
                f"   - Donne une r√©ponse EN FRAN√áAIS uniquement.\n"
                f"   - Fais des paragraphes, sois √©quilibr√© et nuanc√©.\n"
                f"   - Mentionne EXPLICITEMENT les risques s√©curit√©/politique si n√©cessaire.\n"
                f"   - NE PAS utiliser de format liste ni d'emojis.\n\n"
                f"2. Sinon (si l'utilisateur veut juste des id√©es) :\n"
                f"   - Sugg√®re 3-4 destinations.\n"
                f"   - Format OBLIGATOIRE: Nom - raison courte.\n"
                f"   - N'utilise JAMAIS d'emojis."
            )
        
        else:  # general
            user_prompt = f"L'utilisateur dit : '{context.get('message', '')}'\nR√©ponds EN FRAN√áAIS. Sois sympathique mais sans utiliser d'emojis. Si la question porte sur la s√©curit√© ou un avis (ex: Iran, Cor√©e du Nord...), sois nuanc√© et mentionne les risques √©ventuels. Sois bref."
        
        messages = [
            {"role": "system", "content": system_message},
            {"role": "user", "content": user_prompt}
        ]
        
        try:
            # Cr√©er un OllamaGateway frais pour chaque requ√™te pour √©viter
            # les probl√®mes de r√©utilisation de client (client est ferm√© apr√®s sortie de contexte)
            async with OllamaGateway() as gateway:
                result = await gateway.chat_completion(
                    messages=messages,
                    temperature=0.7,
                    max_tokens=650
                )
                return result["content"]
        
        except Exception as e:
            logger.error(f"G√©n√©ration Ollama √©chou√©e : {e}")
            # Fallback vers des templates simples
            return self._fallback_response(prompt_type, context)
    
    def _fallback_response(self, prompt_type: str, context: Dict) -> str:
        """Solution de repli lorsque Ollama est indisponible."""
        dest = context.get('destination', 'votre destination')
        
        fallbacks = {
            "navigate_to_flights": f"Je vous am√®ne √† la recherche de vols pour {dest}.",
            "navigate_to_hotels": f"Je vous am√®ne √† la recherche d'h√¥tels √† {dest}.",
            "navigate_to_packages": f"Je vous am√®ne √† la recherche de packages pour {dest}.",
            "clarification": "Pouvez-vous me donner plus de d√©tails ?",
            "inspiration": (
                "Voici quelques destinations populaires :\n\n"
                "üóº **Paris** - Culture, gastronomie, monuments historiques\n"
                "üóæ **Tokyo** - Technologie, temples, cuisine exceptionnelle\n"
                "üóΩ **New York** - Ville dynamique, shopping, arts\n"
                "üèñÔ∏è **Barcelone** - Plages, architecture, vie nocturne\n\n"
                "Laquelle vous int√©resse ?"
            ),
            "general": "Comment puis-je vous aider dans votre voyage ?"
        }
        
        return fallbacks.get(prompt_type, fallbacks["general"])
    
    async def _handle_flight_search(self, entities: Dict, user_message: str) -> Dict:
        """G√©rer l'intention de recherche de vol."""
        destination = entities.get("destination")
        
        if not destination:
            response = await self._generate_ollama_response(
                "clarification",
                {"missing": "la destination"}
            )
            return {
                "action": "chat_only",
                "target_view": None,
                "prefill_data": None,
                "search_results": None,
                "response_text": response,
                "metadata": {"needs_clarification": True}
            }
        
        # Naviguer vers la vue vols avec destination pr√©-remplie
        response = await self._generate_ollama_response(
            "navigate_to_flights",
            {"destination": destination}
        )
        
        return {
            "action": "navigate",
            "target_view": "flights",
            "prefill_data": {"destination": destination},
            "search_results": None,
            "response_text": response,
            "metadata": {"destination": destination}
        }
    
    async def _handle_hotel_search(self, entities: Dict, user_message: str) -> Dict:
        """G√©rer l'intention de recherche d'h√¥tel."""
        destination = entities.get("destination")
        
        if not destination:
            response = await self._generate_ollama_response(
                "clarification",
                {"missing": "la ville"}
            )
            return {
                "action": "chat_only",
                "target_view": None,
                "prefill_data": None,
                "search_results": None,
                "response_text": response,
                "metadata": {"needs_clarification": True}
            }
        
        response = await self._generate_ollama_response(
            "navigate_to_hotels",
            {"destination": destination}
        )
        
        return {
            "action": "navigate",
            "target_view": "hotels",
            "prefill_data": {"destination": destination},
            "search_results": None,
            "response_text": response,
            "metadata": {"destination": destination}
        }
    
    async def _handle_package_search(self, entities: Dict, user_message: str) -> Dict:
        """G√©rer l'intention de recherche de package."""
        destination = entities.get("destination")
        
        if not destination:
            response = await self._generate_ollama_response(
                "clarification",
                {"missing": "la destination"}
            )
            return {
                "action": "chat_only",
                "target_view": None,
                "prefill_data": None,
                "search_results": None,
                "response_text": response,
                "metadata": {"needs_clarification": True}
            }
        
        response = await self._generate_ollama_response(
            "navigate_to_packages",
            {"destination": destination}
        )
        
        return {
            "action": "navigate",
            "target_view": "packages",
            "prefill_data": {"destination": destination},
            "search_results": None,
            "response_text": response,
            "metadata": {"destination": destination}
        }
    
    async def _handle_inspiration(self, entities: Dict, user_message: str) -> Dict:
        """G√©rer les demandes d'inspiration avec suggestions contextualis√©es."""
        # Passer le contexte extrait √† Ollama pour des suggestions personnalis√©es
        context = {
            "period": entities.get("period"),
            "preferences": entities.get("preferences", []),
            "message": user_message
        }
        
        response = await self._generate_ollama_response(
            "inspiration",
            context
        )
        
        return {
            "action": "chat_only",
            "target_view": None,
            "prefill_data": None,
            "search_results": None,
            "response_text": response,
            "metadata": {
                "inspiration": True,
                "context": context
            }
        }
    
    async def _handle_booking_history(self, entities: Dict, user_message: str) -> Dict:
        """G√©rer l'intention d'historique de r√©servation."""
        # Naviguer vers la vue historique
        response = await self._generate_ollama_response(
            "general", # Confirmation g√©n√©rique
            {"message": "Je vous affiche votre historique de r√©servations."}
        )
        return {
            "action": "navigate",
            "target_view": "history", # En supposant que cette vue existe
            "prefill_data": None,
            "search_results": None,
            "response_text": response,
            "metadata": {"intent": "booking_history"}
        }

    async def _handle_budget_advice(self, entities: Dict, user_message: str) -> Dict:
        """G√©rer l'intention de conseil budg√©taire."""
        # Chat uniquement pour l'instant
        response = await self._generate_ollama_response(
            "general",
            {"message": user_message} # Laisser Ollama g√©rer le conseil
        )
        return {
            "action": "chat_only",
            "target_view": None,
            "prefill_data": None,
            "search_results": None,
            "response_text": response,
            "metadata": {"intent": "budget_advice"}
        }

    async def _handle_general_conversation(self, user_message: str) -> Dict:
        """G√©rer la conversation g√©n√©rale."""
        response = await self._generate_ollama_response(
            "general",
            {"message": user_message}
        )
        return {
            "action": "chat_only",
            "target_view": None,
            "prefill_data": None,
            "search_results": None,
            "response_text": response,
            "metadata": {"intent": "general"}
        }
